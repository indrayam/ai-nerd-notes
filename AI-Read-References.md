# AI Reading References

## Reading Set 4
- [Towards Democratizing RL for LLMs](https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2)
  - Source: [This is wild - UC Berkeley shows that a tiny 1.5B model beats o1-preview on math by RL!...](https://x.com/Yuchenj_UW/status/1889387582066401461)
- [Awesome AI/ML resources](https://github.com/armankhondker/awesome-ai-ml-resources)

## Reading Set 3
- [The StatQuest Illustrated Guide to Neural Networks and AI (PDF)](https://statquest.gumroad.com/l/kihdi)
- [The StatQuest Illustrated Guide to Machine Learning (PDF)](https://statquest.gumroad.com/l/wvtmc)
- [Articles About AI and Machine Learning](https://thelmbook.com/articles/#!./DeepSeek-R1.md)
- [Why reasoning models will generalize - by Nathan Lambert](https://www.interconnects.ai/p/why-reasoning-models-will-generalize)
- [Everything You Should - Know About GPTs - Generative Pre-Trained Transformers | Chaithanya - Kumar A](https://chaithanyak.com/machine/learning/2024/03/21/everything-you-need-to-know-about-gpts.html)
- [The 2025 AI Engineering - Reading List - Latent Space](https://www.latent.space/p/2025-papers)
- [The Annotated - Transformer](https://nlp.seas.harvard.edu/annotated-transformer/)
- [Suchir - Balaji: agi view 3 8/14/24](https://docs.google.com/document/d/1ItRqrpgQHJ05rQx0zc26t1_NgpUcw3znwTWpXxqH8uI/mobilebasic)
- [A Visual Guide to Mixture of - Experts (MoE)](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts)
- [The Illustrated DeepSeek-R1 - by Jay Alammar](https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1)
- [Introduction to - Embeddings at Cohere — Cohere](https://docs.cohere.com/v2/docs/embeddings)
- [Embedding models · Ollama - Blog](https://ollama.com/blog/embedding-models)
- [LLM - Quantization: Techniques, Advantages, and Models](https://www.tensorops.ai/post/what-are-quantized-llms)
- [A Visual and - Interactive Guide to the Basics of Neural Networks – Jay Alammar](https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/)
- [A Visual And - Interactive Look at Basic Neural Network Math – Jay Alammar](https://jalammar.github.io/feedforward-neural-networks-visual-interactive/)
- [Visualizing A Neural Machine Translation Model - (Mechanics of Seq2seq Models With Attention) – Jay Alammar](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
- [The Illustrated - Transformer – Jay Alammar](https://jalammar.github.io/illustrated-transformer/)
- [The Illustrated BERT, - ELMo, and co. (How NLP Cracked Transfer Learning) – Jay Alammar](https://jalammar.github.io/illustrated-bert/)
- [The Illustrated GPT-2 - (Visualizing Transformer Language Models) – Jay Alammar](https://jalammar.github.io/illustrated-gpt2/)
- [How GPT3 Works - Visualizations and Animations – Jay Alammar](https://jalammar.github.io/how-gpt3-works-visualizations-animations/)
- [The Illustrated - Word2vec – Jay Alammar](https://jalammar.github.io/illustrated-word2vec/)
- [The - Illustrated Stable Diffusion – Jay Alammar](https://jalammar.github.io/illustrated-stable-diffusion/)
- [Transformers from Scratch](https://www.brandonrohrer.com/transformers)
- [Visualize LLM](https://t.co/DPH5wBte2D)
  - Source: [Everyone should be using this website to understand the inside of an LLM...](https://x.com/deedydas/status/1889511316903411894?s=43)

## Reading Set 2
- [Using - pip to install a Large Language Model that’s under 100MB](https://simonwillison.net/2025/Feb/7/pip-install-llm-smollm2/)
- [simonw/files-to-prompt: - Concatenate a directory full of files into a single prompt for use - with LLMs](https://github.com/simonw/files-to-prompt)
- [Modular: - Democratizing Compute, Part 1: DeepSeek’s Impact on AI](https://www.modular.com/blog/democratizing-compute-part-1-deepseeks-impact-on-ai)
- [Simon - Willison on X: "Published some notes on S1, a new reasoning model that - was fine-tuned from Qwen 2.5 32B on just 1,000 examples and $6 of - compute Includes notes on running it with Ollama and exploring those 1,- 000 examples with Datasette Lite https://t.co/wFkxj5neDn"](https://x.com/simonw/status/1887230653399507016?s=43)
- [Simon - Willison on X: "Updated my post to add the results of my "Generate an SVG of a pelican riding a bicycle" benchmark](https://x.com/simonw/status/1887198978334482514?s=43)
- [The - Truth About Few-Shot Prompting.](https://www.lycee.ai/blog/the-truth-about-few-shot-prompting)
- [Chaithanya Kumar on X: "Hey folks I started getting deep into - understanding how LLMs are built from the ground up ( I am always of - the opinion that if you don't understand how something works from - first principles, you will never be able to make the best out of it. ) - Below are my resources 1. https://t.co/PNBlT79mSw"](https://x.com/chaithanyak42/status/1884620928627150998?s=58)
- [Understanding Reasoning LLMs - by Sebastian Raschka, PhD](https://magazine.sebastianraschka.com/p/understanding-reasoning-llms)
- [Emerging - Patterns in Building GenAI Products](https://martinfowler.com/articles/gen-ai-patterns/#rag)
- [A Visual Guide to Reasoning LLMs - by Maarten Grootendorst](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-reasoning-llms)

## Reading Set 1
- [AI Papers](https://www.dropbox.com/scl/fo/2iah7adye9yx70u1keubq/AJ6c0z7Q5y4ZYVZOKmstO6o?rlkey=nq9w9fjx8wb71qi09gf03g45a&e=1&st=s437yxm3&dl=0)

## AI Skills
- [AI Skills](https://github.com/indrayam/ai-nerd-notes)

## AI References
- [AI Learning Resources](https://github.com/indrayam/ai-nerd-notes/blob/main/AI-Learning-Resources.md)
- [AI Watch References](https://github.com/indrayam/ai-nerd-notes/blob/main/AI-Watch-References.md)

